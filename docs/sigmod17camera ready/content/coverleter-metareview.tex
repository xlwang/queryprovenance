%!TEX root = ../main.tex


\section*{Comments by Meta-Reviewer}

\noindent
\textbf{Comment \#1:} Slicing soundness
\begin{quote}
\reviewer{
Discuss and clarify the soundness of slicing techniques.
}
\end{quote}

We have added discussion in Sections~\ref{sec:opt:tbsize},
\ref{sec:opt:query}, and~\ref{sec:opt:attslice} on the soundness of the three
slicing methods.  We give the summary here:

In the general case, tuple slicing is a heuristic method. It decomposes a
large MILP problem into two, typically much smaller, MILP problems. It is
effective in practice and greatly helps improve \sys performance, especially
when the ratio of the complaint set size and the database size is small. In
general, this heuristic can result in incorrect repairs. This is possible if a
query $q$ succeeds an erroneous query $q_e$, and $q$ overwrites all changes by
$q_e$. However, \emph{tuple slicing is sound in certain settings}, namely,
when the complaint set is complete and if corruptions are limited to a single
query. In these cases, by using incremental repair
(Section~\ref{sec:incremental}) and by disallowing all non-complaint tuples in
the refinement step (e.g., by restricting the value of the objective function
in the refinement MILP to zero), the solver will be forced to pick the correct
repair.



The query and attribute slicing optimizations are always sound, in the sense
that \sys will produce the same repairs when these optimizations are applied
as when they are not. These slicing methods remove from the problem any
queries and attributes, respectively, that could not have have had an impact
to the incorrect values in the complaints. More specifically,
\emph{query-slicing} computes the \emph{full-impact} of each query, which is a
form of forward provenance: starting at query $q$, and tracing the log forward
(toward more recent queries) we keep track of all attributes that may have
been modified by $q$. If the full-impact of $q$ does not intersect with any
incorrect attributes in the complaint set, it is guaranteed that $q$ does not
affect any of the errors reported in the complaint set. Similarly, attribute
slicing summarizes all attributes that may have been modified by or define
predicates in queries in the history. Any attributes that are not on this list
can be safely ignored. Thus, applying query or attribute slicing will never
reduce the accuracy of \sys. We formalize this result in
Lemma~\ref{lem:sound}.


 
\comskip

\noindent
\textbf{Comment \#2:} Clarifications
\begin{quote}
\reviewer{
Clarify the assumptions, their interaction, and why they are realistic in practice. clarify that the system is not repairing the update queries, but the affected data (i.e., query is not correct and errors can still happen).}
\end{quote}

We have edited the text in Section~\ref{sec:abstractions} to emphasize all assumptions used by \sys.  We summarize the main points here.

The first set of assumptions pertain to the focus of our system: \sys
identifies and repairs errors in query parameters, but does not modify the
query structure. Further, it is restricted to relatively simple OLTP queries
with no subqueries, aggregation, joins, or user-defined functions (UDFs).
These restrictions are realistic for a broad range of user-facing web
applications and OLTP benchmarks, as complex query structures and operations
are less common in update workloads than in read-oriented analytical
workloads. In addition, \sys makes the implicit assumption that the log starts
either with an empty or a clean database. While \sys can still be employed in
settings where this assumption does not hold, it would not be able to resolve
complaints that pertain to errors that existed before the start of the query
history.

We have also clarified in Sections~\ref{sec:abstractions} and~\ref{sec:opt}
the role of two additional restrictions in our framework: completeness of the
complaint set, and single-query corruptions. Under these assumptions, \sys can
take advantage of powerful optimizations. However, \sys is not restricted to
settings where these assumptions hold, and can handle cases of multiple query
corruptions and incomplete complaints. The effectiveness and efficiency of
\sys can be limited in these settings, mostly due to limitations of the MILP
solvers. Improvements in MILP technologies will also improve \sys's
capabilities. In our evaluation, we study these cases empirically, and we have
included experiments with incomplete complaints and multiple query corruptions
(Section~\ref{sec:experiments:hardprob}).

Finally, we have also clarified in Section~\ref{sec:abstractions}, that while
we define complaints as complete records, we do so only for ease of
exposition. This is not an inherent restriction of \sys and definitions and
algorithms can be trivially extended to handle unknown values.



\comskip

\noindent
\textbf{Comment \#3:} Larger data sizes
\begin{quote}
\reviewer{
Add experiment with larger data size, or clarify why they cannot be done.}
\end{quote}

% We extend our experiment with larger database sizes in Figure~\ref{f:attr100}
% with up to $100k$ tuples.
We apologize for the apparent inconsistency between the text and the graphs in
the experiments. In our original submission, the graphs depicting the
experiments on larger datasets were in the appendix
(Appendix~\ref{sec:heuristic}).

For the revision, we further extended our experiments and augmented
Figure~\ref{f:attr100} to datasets of up to $100K$ records. This experiment
uses the most complex setting (\texttt{UPDATE} queries with \textit{range}
\texttt{WHERE} clause), and shows that \sys is efficient for datasets of
$100K$ records, even when the query corruption is not recent.

% \alex{We should add a couple more sentences here to apologize for the
% apparent inconsistency, and say that the 100k experiments were in the
% appendix, but they are now in the main paper. Did we just move an experiment,
% or did we augment the presented results?}


\comskip

\noindent
\textbf{Comment \#4:} Error generation
\begin{quote}
\reviewer{
Investigate how many of the errors exhibit interesting patterns (such as a
later update masking the effect of an earlier erroneous one). If there are
already lots of examples of this, compare effectiveness on the ``simple''
errors with the ``complex'' ones; otherwise, you should improve the test data
generator.
}
\end{quote}

We have added a new section in the appendix (Appendix~\ref{app:selectivity}),
that analyzes the interactions of the queries we synthetically generate. Our
synthetic data generator does not directly control the degree of interaction
among queries in the log, but parameters such as the number of attributes and
the dataset size impact this directly. We show that the probability that any
two \texttt{UPDATE} queries with range predicates interact (i.e., the
intersection of the tuples they update is non-empty) is actually quite high
under the default settings of our data generator (about 0.31).

The level of query interactions greatly influences the hardness of the problem
as errors may propagate differently under different scenarios. There are many
factors that may affect the level of query interactions. In general,
\texttt{UPDATE} queries interact with each other more than \texttt{INSERT} or
\texttt{DELETE} queries. Figure~\ref{f:indelup_time} shows that \sys is less
efficient in \texttt{UPDATE} workloads. This is in large part because the
query interactions in this setting are more complex. Within the class of
\texttt{UPDATE} queries, larger range selectivities also result in more
interactions, thus increasing runtime (Figure~\ref{f:qidx_time}). Another
factor that affects query interactions is the number of attributes in the
schema. With fewer attributes, updates are more likely to interact, again
affecting runtime Figure~\ref{f:attr}. We also evaluate \sys over different
query selectivities. In Figure~\ref{f:selectivityvstime}, we observe that the
execution time of \sys increases with larger query ranges, which results in
higher query interaction.


% To carefully evaluate \sys's performance over problems with different
% properties, we introduce a synthetic data generator in Section~\ref{sec:setup}
% with multiple adjustable parameters, including query type, workload and
% database size, and query selectivity. With the help of these parameters, we
% are able to control one of the key properties in the workload, the interaction
% of the queries, and thus to better understand \sys's performance. The level of
% query interactions greatly influences to the hardness of the problem as errors
% may propagate differently under different scenarios.

% There are many factors that may affect the level of query interactions. In
% general, \texttt{UPDATE} queries are heavily interact with each other than
% \texttt{INSERT} or \texttt{DELETE} queries since tuples persist in the
% database and may be continuously updated by the following \texttt{UPDATE}
% queries. We demonstrate this in Figure~\ref{f:indelup_time} and observe that
% under the same corruption age, \texttt{UPDATE}-workload requires longer time
% to solve than \texttt{DELETE} and \texttt{INSERT}-workloads. For
% \texttt{UPDATE} queries, \textit{constant} \texttt{SET} clauses do not require
% former attribute value(s), and thus have less query interaction compare to
% queries with \textit{relative} \texttt{SET} clauses
% (Figure~\ref{f:qidx_time}). Under default parameters, \texttt{UPDATE} queries
% with \textit{point} \texttt{WHERE} clauses update less amount of tuples than
% queries with \textit{range} \texttt{WHERE} clauses. Thus, the first type
% oftentimes has lower level of query interaction and easier to solve in
% practice (Figure~\ref{f:qidx_time}). For \texttt{UPDATE} queries with
% \textit{range} \texttt{WHERE} clauses, we found that both the number of
% attributes $N_a$ and query selectivity $s$ may strongly influence the level of
% query interaction (Appendix~\ref{app:selectivity}). Under our default setting,
% increase the number of attribute $N_a$ reduces the query interaction and thus
% we observe that problems with larger number of $N_a$ are easier to solve in
% Figure~\ref{f:attr}. On the other hand, increasing query selectivity $s$ means
% more tuples are updated by each query and thus leads to higher level of query
% interaction. Thus, higher query selectivity leads to longer solving time.



\comskip

\noindent
\textbf{Comment \#5:} Possible baselines
\begin{quote}
\reviewer{
Implementation of a baseline (described in the review) or explain why such
baselines would fail in the context, to convince readers that complex patterns
can be handled only by this new system.
}
\end{quote}

\sys solves two challenges in combination: (1)~it traces the cause of a set of
errors (complaints) to parameters of the queries in the log, and (2)~it
produces a query repair that revises all complaints to their correct values. The
existing work suggested by Reviewer 3~\cite{Wu13, roy2014formal,
chalamalla2014,meliou2011tracing} has strong connections to the first of these
two challenges: under certain problem settings, all of these techniques focus on
explaining or finding the causes of query results from the input data. While
this exhibits strong connections with the problem setting of \sys, we found
that none of these approaches can be used in our setting, either because of
prohibitive assumptions, or because of extreme explosion in the problem
size~(\cite{meliou2011tracing}). We provide a detailed explanation for each of
these techniques in our response to Reviewer 3\# Comment 2. In addition, none
of these methods addresses the second problem, of producing repairs.

We have augmented our related work to highlight these points.


