%!TEX root = ../main.tex

\section{Related Work}
\label{s:related}
\sys tackles the problem of diagnosis and repair in relational query
histories (query logs). It does not aim to correct errors in the data
directly, but rather to find the underlying reason for reported errors
in the queries that operated on the data. This is in contrast to
traditional data 
cleaning~\cite{dallachiesa2013nadeef,Abiteboul99,Koudas2006,Galhardas2000
} which oftentimes focuses on identifying and correcting data
``in-place.''. \sys also differs from another aspect of data cleaning which 
focuses on providing repairs for the
identified errors~\cite{Fan2008b, ChuIP13, Beskales2010, Cong2007}.
In fact, by analyzing the process that generate the errors. 
\sys detects and repairs systemic 
errors even if they have not been explicitly identified.

The concept of exploring systemic reasons and patterns for errors has been
applied in tools ~\cite{GolabKKS10, wang2015} that 
generate feature sets or patterns of attributes that characterize
errors. However, such techniques are oblivious to
the actual queries that operated on the data, and they do not provide
particular fixes. 

%% Query revisions for why-not
The topic of query revisions has been studied in the context of
why-not explanations~\cite{Chapman2009, tran2010conquer,tzompanaki14semi } and explaining query ouputs ~\cite{GebalyAGKS14,Wu13,Roy2014}. 
But all these approaches are
limited to selection predicates of \texttt{SELECT} queries, and they
only typically consider one query at a time.

Finally, as \sys traces errors in the queries that manipulate data, it
has connections to the field of \emph{data and workflow provenance}.
our algorithms build on several formalisms introduced by work in this
domain. These formalisms express why a particular data item appears in
a query result, or how that query result was produced in relation to
input data~\cite{BunemanKT01,GKT07-semirings, CheneyCT09, CuiWW00
}.

% Studying and explaining
% data outcome has been studied in many aspects:
% \cite{GebalyAGKS14}
% focuses on providing 
% explanations to particular data outcome in tables; \cite{wang2015}
% provides error diagnosing for general data extraction systems. 

% 
% % things  about validating updates before executing/cmmit to database
% Related work about validating updates in time: 
% \cite{Chen2011} validate correctness of updates before performing the update;
% 
% 
% % things for exploring wrong or undetermined query,  why not? 
% Related works on deriving desired select query: focus on 
% Query by example, \cite{dimitriadou2014explore}  uses machine learning
% techniques to explore query that satisfy user interests. 
% 
% 
% % things about data provenance and data debugging
% \cite{mucslu2013data}
% 
% 
% 
% Scorpion explanation uses data to synthesize predicates that explain.
% 
% 
% View construction and query by example.
% 
% Take a look at temporal databases, the CIDR/arxiv paper has a few good starting points. Aditya also dug these out a while back
% 
% 
% The way we return results is more like online aggregation or anytime algorithms -- 
% as you run longer, the suggested fixes improve because we examine more of the query log.
% 
% \url{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.49.3765&rep=rep1&type=pdf}
% 
% \url{http://people.cs.aau.dk/~csj/Thesis/pdf/chapter26.pdf}
