%!TEX root = ../main.tex

\section{Related Work}
\label{s:related}

% data cleaning
\sys tackles the problem of diagnosis and repair in relational query
histories (query logs). It does not aim to correct errors in the data
directly, but rather to find the underlying reason for reported errors
in the queries that operated on the data. This is in contrast to
traditional data cleaning~\cite{dallachiesa2013nadeef, rahm00, Raman01, Kalashnikov06,
Fan2008b} which focuses on identifying and correcting data
``in-place.'' Identifying and correcting errors is an important, and
rightfully well-studied problem. Existing literature has supplied a
variety of tools to capture errors originating from data
integration~\cite{Abiteboul99, Batini1986, Rahm2001, ParentS98},
recognizing the same entities in data~\cite{Koudas2006,
GruenheidDS14}, identifying true facts among conflicting
data~\cite{yin2008truth, DN09, ltm2012}, and language support for
cleaning~\cite{Galhardas2000}. All of these techniques are
complimentary to our work. Their goal is to identify which data is
correct and which data is incorrect, but they don't look for the
sources of these errors in the processes or queries that generate and
modify this data. In fact the output of such methods can be used to
augment the complaint sets used by \sys, which focuses on identifying
errors in the queries that produced the data, rather than the data
itself.

%repairs
An aspect of data cleaning focuses on providing repairs for the
identified errors~\cite{ChuIP13}. Tools in this domain have targeted
different methods and interactions for providing fixes, ranging from
functional dependencies~\cite{Fan2008b, ChuIP13} and
rules~\cite{Beskales2010, Cong2007} and functional
dependencies~\cite{Fan2008b, ChuIP13}, to interactive methods that
solicit user feedback~\cite{Yakout, Raman01}. As with the other data
cleaning approaches, all these techniques again operate on the data
directly. In contrast, \sys analyzes errors in the data to diagnose
and repair errors in queries that operated on the data. Thus, \sys
leverages the facts that some data errors are systemic, linked to
erroneous updates. Diagnosing the cause of the errors, will achieve
systematic fixes that will correct all relevant errors, even if they
have not been explicitly identified.

%% Data auditor and Data XRay
Closer to exploring systemic reasons and patterns for errors are
techniques such as Data Auditor~\cite{Golab2008, GolabKKS10} and Data
X-Ray~\cite{wang2015}. Both tools tools identify features, which can
be selected from the tuple attributes, that best summarize or describe
groups of tuples (or specifically errors). While these tools can
generate feature sets or patterns of attributes that characterize
errors, these are not linked to the queries, but are again
characterizations over the data itself. Such techniques can be
tremendously useful if the processes that generate or modify the data
are unknown or black-box computations. In these cases, Data Auditor
and Data X-Ray can provide high-level clues for potential problems in
the data derivation process. However, both approaches are oblivious to
the actual queries that operated on the data, and they do not provide
particular fixes. Ontology-based why-not
explanations~\cite{tenCate2015} is very similar to Data X-Ray, but is
only relevant to absent tuples (deletions), and again does not
consider the query history.

%% Query revisions for why-not
The topic of query revisions has been studied in the context of
why-not explanations~\cite{Chapman2009}. These scenarios investigate
the absence of answers in a query result, and often attempt to modify
the query to change its outcome. Skyline
refinement~\cite{tran2010conquer} focuses specifically on refinements
that use skyline queries, while semi-automatic SQL
debugging~\cite{tzompanaki14semi} revises a given query to make it
return specified tuple groups in its output. All these approaches are
limited to selection predicates of \texttt{SELECT} queries, and they
only typically consider one query at a time. In contrast, \sys handles
update workloads, processes large query histories, and can model
several steps in the dataset's evolution.

%things about diagnosis and explanations
Existing work on explaining query outputs~\cite{GebalyAGKS14} is also
limited in its applicability. The Scorpion system~\cite{Wu13}
processes a set of outlier points in an aggregate to identify
predicates on the input data as explanations. Roy and
Suciu~\cite{Roy2014} extended explanations with a formal framework
that handles complex SQL queries and database schemas involving
multiple relations and functional dependencies, but again their focus
is on \texttt{SELECT} workloads, rather than evolving datasets, and
they often target specific application domains~\cite{Khoussainova2012,
Thirumuruganathan2012, Das2011, Fabbri2011, Bender14}.

% Studying and explaining
% data outcome has been studied in many aspects:
% \cite{GebalyAGKS14}
% focuses on providing 
% explanations to particular data outcome in tables; \cite{wang2015}
% provides error diagnosing for general data extraction systems. 

% 
% % things  about validating updates before executing/cmmit to database
% Related work about validating updates in time: 
% \cite{Chen2011} validate correctness of updates before performing the update;
% 
% 
% % things for exploring wrong or undetermined query,  why not? 
% Related works on deriving desired select query: focus on 
% Query by example, \cite{dimitriadou2014explore}  uses machine learning
% techniques to explore query that satisfy user interests. 
% 
% 
% % things about data provenance and data debugging
% \cite{mucslu2013data}
% 
% 
% 
% Scorpion explanation uses data to synthesize predicates that explain.
% 
% 
% View construction and query by example.
% 
% Take a look at temporal databases, the CIDR/arxiv paper has a few good starting points. Aditya also dug these out a while back
% 
% 
% The way we return results is more like online aggregation or anytime algorithms -- 
% as you run longer, the suggested fixes improve because we examine more of the query log.
% 
% \url{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.49.3765&rep=rep1&type=pdf}
% 
% \url{http://people.cs.aau.dk/~csj/Thesis/pdf/chapter26.pdf}
