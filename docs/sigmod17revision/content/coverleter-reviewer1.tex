\section*{Comments by Reviewer 1}

\noindent
\textbf{Comment \#1:} Slicing soundness
\begin{quote}
\reviewer{
What are the soundness/correctness properties needed for the slicing
heuristics to be applicable/useful?

\dots

Unclear whether (or why) slicing techniques are ``sound'', or whether they
would be useful on realistic data rather than synthetic / randomly generated
benchmark data.

\dots

p6. Why is tuple slicing sound? It sounds like it will amount to modeling only
the tuples that are subject to a complaint...

\dots

p7. Likewise, I'm not convinced query or attribute slicing are safe
optimizations.
\dots  
this requires proof

}
\end{quote}

We have added discussion in Sections~\ref{sec:opt:tbsize},
\ref{sec:opt:query}, and~\ref{sec:opt:attslice} on the soundness of the three
slicing methods.   


In the general case, tuple slicing is a heuristic method. It decomposes a
large MILP problem into two, typically much smaller, MILP problems. It is
effective in practice and greatly helps improve \sys performance, especially
when the ratio of the complaint set size and the database size is small. In
general, this heuristic can result in incorrect repairs. This is possible if a
query $q$ succeeds an erroneous query $q_e$, and $q$ overwrites all changes by
$q_e$. Under a more complex scenario, where tuples are dependent to 
each other (as mentioned in comments ``p6...''), tuple-slicing is more likely 
to make mistakes as it under-specify many dependent tuples that are 
not in the complaint set. 
However, \emph{tuple slicing is sound in certain settings}, namely,
when the complaint set is complete and if corruptions are limited to a single
query. In these cases, by using incremental repair
(Section~\ref{sec:incremental}) and by disallowing all non-complaint tuples in
the refinement step (e.g., by restricting the value of the objective function
in the refinement MILP to zero), the solver will be forced to pick the correct
repair.

To conclude, \emph{tuple-slicing} is heuristic method that often helps   
improving execution efficiency of \sys in solving workloads with diverse properties. 
Although we don't have any realistic workload data, by examining various  
simulation benchmarks in different application domains~\cite{oltpbench}, we found most of them
share the same properties as we evaluated in Section~\ref{sec:experiments:benchmark}. 
Thus, we believe tuple-slicing does not limit to synthetic / randomly
generated benchmark workloads, instead, it could be applied on realistic workloads as well. 



The query and attribute slicing optimizations are always sound, in the sense
that \sys will produce the same repairs when these optimizations are applied
as when they are not. These slicing methods remove from the problem any
queries and attributes, respectively, that could not have have had an impact
to the incorrect values in the complaints. More specifically,
\emph{query-slicing} computes the \emph{full-impact} of each query, which is a
form of forward provenance: starting at query $q$, and tracing the log forward
(toward more recent queries) we keep track of all attributes that may have
been modified by $q$. If the full-impact of $q$ does not intersect with any
incorrect attributes in the complaint set, it is guaranteed that $q$ does not
affect any of the errors reported in the complaint set. Similarly, attribute
slicing summarizes all attributes that may have been modified by or define
predicates in queries in the history. Any attributes that are not on this list
can be safely ignored. Thus, applying query or attribute slicing will never
reduce the accuracy of \sys. We formalize this result in
Lemma~\ref{lem:sound}.


\alex{Add details, not just references to different responses, as it is hard
for reviewers to go back and forth.}


\comskip

\noindent
\textbf{Comment \#2:} Correction
\begin{quote}
\reviewer{
Please correct definition 6.

\dots

Suppose we have three queries \dots

}
\end{quote}

\alex{The definition needs to be corrected, and more details should be added
here.}

We apologize for the unclear definition and we have clarified it in Definition~\ref{eq:dependency}.
The impact of a query covers a set of attributes that may updated by 
the query. We trace the query 
history to search and expand the impact of a query. More specifically, given a query 
$q_i$, we compute its full-impact $\mathcal{F}(q_i)$ by explicitly 
comparing with each query in the query history in their execution order. 

\noindent In the example reviewer suggested:\\
\textit{\indent $q_1$ writes t.A; \\
\indent $q_2$ reads t.A and writes u.B; \\
\indent $q_3$ reads u.B and writes v.C.}\\
When computing the full-impact of query $q_1$, we start from the impact of $q_1$
on $q_1$, $\mathcal{F}_1(q_1) = \{t.A\}$; and then we move to the next query $q_2$. 
Since $\mathcal{F}_1(q_1)  \cap\mathcal{P}(q_2) \neq \emptyset$, we extend the impact 
of $q_1$ on $q_2$ as $\mathcal{F}_2(q_1) = \{t.A, u.B\}$. Similarly, with 
$\mathcal{F}_2(q_1)  \cap\mathcal{P}(q_3) \neq \emptyset$, we conclude the full-impact
of $q_1$ as $\{t.A, u.B, v.C\}$.


\comskip

\noindent
\textbf{Comment \#3:} Experiments on large datasets
\begin{quote}
\reviewer{
Do the experiments substantiate the claim of scalability to ``large''
databases of 100k records? If so the experimental evaluation needs to explain
this more clearly. If not the introduction must avoid overselling this point.

\dots

Experimental evaluation doesn't live up to claims in introduction (5-6K
records vs. 100K)

\dots

the experiments only seem to consider much smaller databases (5000-6000
tuples).

}
\end{quote}

We apologize for the apparent inconsistency between the text and the graphs in
the experiments. In our original submission, the graphs depicting the
experiments on larger datasets were in the appendix
(Appendix~\ref{sec:heuristic}).

For the revision, we further extended our experiments and augmented
Figure~\ref{f:attr100} to datasets of up to $100K$ records. This experiment
uses the most complex setting (\texttt{UPDATE} queries with \textit{range}
\texttt{WHERE} clause), and shows that \sys is efficient for datasets of
$100K$ records, even when the query corruption is not recent.


\comskip

\noindent
\textbf{Comment \#4:} Why $M^+$ in \texttt{DELETE} query?
\begin{quote}
\reviewer{
It's also not entirely clear why it is correct to use a ``large/unused'' value $M^+$ for attributes of deleted tuples.

\dots

p5. Handling DELETE using $M^+$. \dots I'm not sure I understand why this the
case and if so, why it is correct. \dots for example if the test is ``t.A > 5'' then setting t.A to $M^+$ (assuming it's bigger than 5) will not invalidate the test.

}
\end{quote}

\alex{Make sure to address both points!}

In this paper, we introduce a \emph{``ghost''} value, 
$M^-$\footnote{For clarification we rename the former variable $M^+$ as $M^-$ to distinguish
from $M$ and emphasis its relationship with $M$ since $M^- \leq M$.}, outside of the attribute domain
to encode the deleted tuple.
Since $M^-$ is outside of the attribute domain, any subsequent conditional functions will
evaluate to false, so subsequent queries do not affect ghost tuples. There are
nuances to how $M^-$ is set. It needs to be sufficiently large, for the MILP
problem to prioritize a modification to the \texttt{WHERE} clause of the
\texttt{DELETE} query ($\sigma_{q_i}(t) = 0/1$), compared to a modification of
the \texttt{SET} clause of an \texttt{UPDATE} query to the ghost value
($\mu_{q_i}(t.A_j) = M^-$). However, it should be $M^- \leq M $ to ensure the
constraints remain feasible (Equation~\ref{eq:uv}). These considerations
ensure that the ghost assignment will not affect subsequent queries.

Note that for workloads with both \texttt{DELETE} and \texttt{UPDATE} queries.
The assignment of $x_{q_i, t}$ in a \texttt{UPDATE} query 
requires the following changes:
$x_{q_i, t} = x'_{q_i, t} \otimes 0 + (1-x'_{q_i, t}) \otimes \sigma_{q_i}(t)$ and
$x'_{q_i, t}= (t.A_j = M^-) \wedge (t.A_j^* = M^-)$.
This arrangement ensures a deleted tuple will not be updated by the following \texttt{UPDATE} queries. 
In the example in reviewer mentioned in $p5$, suppose a tuple is deleted and values in all attributes are assigned to $M^-$. 
The boolean variable $x'_{q_i, t}$ is set to $1$ and $x_{q_i, t} $ to $0$ for any following \texttt{UPDATE} queries regardless
of their \texttt{WHERE} predicate. Thus, \texttt{UPDATE} queries won't updates values for already deleted tuples. 

\comskip

\noindent
\textbf{Comment \#5:} Assumptions
\begin{quote}
\reviewer{
Problem specification seems restrictive (users need to provide complete,
correct rows as complaints).

\dots

p3. Please clarify whether a complaint needs to specify exact fix values for all fields \dots 
}
\end{quote}

While in the paper we use exact fix values for all fields of a complaint, we
only do so for ease of exposition, and this is actually not a limitation in
our techniques. We have added clarification about this in
Section~\ref{sec:model}.



\comskip

\noindent
\textbf{Comment \#6:} Additional corrections and clarifications

\smallskip

We thank the reviewers for the many detailed comments. We have corrected the
typos, and reworded confusing sentences. We also provide some further notes on
some of the detailed comments below.

\begin{quote}
\reviewer{
p2. Although it is just an example, it does seem like questionable design for
the tax rates for different salary levels to be stored in the query rather
than in the database.
}
\end{quote}

The example is emulating a form-based entry of the tax-rate information, but
we agree that in practice the design would be much more complex. We chose a
substantial simplification to make the example easy to follow and to allow us
to more easily highlight the contributions of our work.

\begin{quote}
\reviewer{
p2. The figures in the example seem wrong (ironically) \dots
}
\end{quote}

Thank you for noting this mistake. We corrected the figure to have the
correct numbers.


\begin{quote}
\reviewer{
p3. This is explained later, but please clarify that the expressions used in
mu and sigma are from a limited language (e.g. arithmetic).
}
\end{quote}

\alex{Have we done anything about this?} \xlw{The explanation and definition is
quite close. We give def and then description. Maybe we should switch the order?}


\begin{quote}
\reviewer{
p3. What does notation ``$D \setminus\{t\}$'' mean (in def 3) if $t = \bot$? No-op? Also,
t* should be allowed to range over $D \cup \{\bot\}$ also to allow for deletion
(as discussed on the next page).
}
\end{quote}

We correct our definition on range of $t$ and $t^*$ as $D \cup \{\bot\}$. The transformation of 
a database state $\mathcal{T}_c(D)$ excludes the complaint tuple $\{t\}$ and replace it with 
$t^*$ with correct values. If $t = \bot$, it means tuple $t$ does not exist in the original
database and should be added into the database; similarly if $t^* = \bot$, the tuple $t$ is in
the original database but should be removed. 

\alex{Have we done anything about this?}

\begin{quote}
\reviewer{
p4. The paper often refers to ``data manipulation queries'', which sounds
self-contradictory to me (a query reads, an update writes). Perhaps just
``updates'' instead of ``data manipulation queries'' ?
}
\end{quote}

We change it as ``data manipulation statements'' that include \texttt{UPDATE},
\texttt{INSERT}, and \texttt{DELETE} queries. We intentionally avoid naming 
them ``update queries'' in order to distinguish from the \texttt{UPDATE} query. 

\alex{This term is only used once in the paper. How about we just change it to
data manipulation statements?}


\begin{quote}
\reviewer{
p5. How strongly does the performance of the MILP solver depend on M (the
upper bound chosen on the value of a given numeric field)? Presumably,
choosing the largest machine-representable number would lead to overflow
problems?
}
\end{quote}

To guarantee the correctness of the \texttt{UPDATE} queries, $M$ must 
be assigned to a value outside the domain range of the corresponding attribute 
because constraints in ~\ref{eq:uv} will be self-contradictory otherwise. For example, 
attribute \textit{human age} has a domain range of $[0, 200]$, in which case $M$ must be 
set to a value that is above $200$. 
In addition, in order to maintain the feasibility for workloads with \texttt{DELETE}
queries, $M$ must be set to a value that is $\geq M^-$ (we explained
the setting of $M^-$ in Comment\# 4), but not necessary a 
upper bound of the given numeric field. 

\alex{Have we done anything about this?}


\begin{quote}
\reviewer{
p5. In (5), should v be u?
}
\end{quote}

We thank the reviewer for noting this, we correct this typo in the paper. 
\alex{(5) does not seem to have changed. If it does not need to be changed, we
should explain here why.} 


\begin{quote}
\reviewer{
p7. ``Figure 3 showed the exponential cost'' - the scaling from 40 to 60 to 80 looked linear to me, just with a high coefficient.}
\end{quote}
We apologize for not stating it clear. In Figure~\ref{fig:querysize_vs_time}, \naive fails to produce an answer
 for problems with $\geq 80$ queries within 1000 sec and \naive shows exponential cost for problems with $20$, $40$, and $60$ queries. 
\alex{What is the answer here?}


\begin{quote}
\reviewer{
p10. Fig. 8 - please add 0.75 (the largest x-axis value) to the x-axis, better yet, label the x-axis with the rate values that correspond to data points.
}
\end{quote}

We thank the reviewer for the detailed suggestion and we implement this in our main text. 

\begin{quote}
\reviewer{
p10. ``may suffer if the corruption occured in a very old query'' - does it (and are you saying fig. 8 supports this claim)?

p10. ``may over-generalize'' - again, are you speculating or interpreting the results here?
}
\end{quote}

We observe from Figure~\ref{f:falsenegative_acc} that \sys derives inaccurate log repairs when the corruption occured in 
very old query  \textit{corruption age = 250}). Also, if there are insufficient complaints, then it is possible that the 
repair will over-generalize to  ``repair'' the wrong records and lead to lower precision.

\alex{What have we done for this?} \xlw{We added some clarification in the text. }

\begin{quote}
\reviewer{
p10, footnote: this seems like a strong assumption! I guess this means that dealing with multiple errors that interact with each other is future work...
}
\end{quote}

We clarify this assumption in Section~\ref{sec:abstractions}. Currently, we cannot apply incremental algorithm 
on problems with multiple corruptions since errors may spread across the entire query history, \sys 
does not scale over problems with more than 40 queries. We leave further improvement in our future work.

\alex{We need to say something here.  Have we clarified this assumption early in the paper?}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
