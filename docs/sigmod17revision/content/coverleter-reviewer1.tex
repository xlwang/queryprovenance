\section*{Comments by Reviewer 1}

\noindent
\textbf{Comment \#1:} Slicing soundness
\begin{quote}
\reviewer{
What are the soundness/correctness properties needed for the slicing
heuristics to be applicable/useful?

\dots

Unclear whether (or why) slicing techniques are ``sound'', or whether they
would be useful on realistic data rather than synthetic / randomly generated
benchmark data.

\dots

p6. Why is tuple slicing sound? It sounds like it will amount to modeling only
the tuples that are subject to a complaint...

\dots

p7. Likewise, I'm not convinced query or attribute slicing are safe
optimizations.
\dots  
this requires proof

}
\end{quote}

\emph{Tuple-slicing} is a \textbf{heuristic} that breaks down a large MILP problem 
into two, often much smaller, MILP problems. It works effectively in practice and 
greatly helps improving \sys's performance, especially when the ratio of complaint 
set size and the database size is small. However, it it possible that \emph{tuple-slicing} 
fixes the incorrect query and introduce noises to the query log repair. In addition, 
under more complex settings where tuples are no longer independent 
(also mentioned in the review ``p6 ...''), \emph{tuple-slicing} 
is more likely to make mistakes. 

In cases where the complaint set is complete and single query error,
 \emph{tuple-slicing} can avoid making mistakes by incorporating other optimization and
  enforcing empty non-complaint set
in the refinement step. 
To conclude, \emph{tuple-slicing} is safe for problems with single query corruption and complete complaint set both synthetic / randomly
generated benchmark workloads and realistic workloads. We plan to improve \sys's ability in handling 
inconsistent complaints, including incomplete complaint set, in our future work.

\emph{Query-slicing} and \emph{attribute-slicing} remove irrelevant queries and attributes 
according to whether or not they would affect the incorrect values in the complaints. 
\sys conducts a throughout analysis by tracing forward the query history and identifies
queries that are not able to modify incorrect attributes in the complaint set. Since adjustment
to such queries has no impact on the erroneous values, it is safe to apply \emph{query-slicing}. 
Similar to \emph{query-slicing}, \emph{attribute-slicing} searches for all attributes that may
modified by queries in the workload (or a subset of queries after applying \emph{query-slicing}) and
avoids encoding attributes that are not in the list into the MILP problem. Thus, \emph{attribute-slicing}
is also safe. 

\alex{Add details, not just references to different responses, as it is hard
for reviewers to go back and forth.}


\comskip

\noindent
\textbf{Comment \#2:} Correction
\begin{quote}
\reviewer{
Please correct definition 6.

\dots

Suppose we have three queries \dots

}
\end{quote}

\alex{The definition needs to be corrected, and more details should be added
here.}

\xlw{Original def. 6 seems misleading, let's verify it.}

The \textbf{full-impact}, $\mathcal{F}(q_i)$, of a query $q_i$ includes all
attributes that may modified by the query $q_i$ and it is calculate by the
intermediate-impact of all its consecutive queries. Let us denote
$\mathcal{F}_j(q_i)$ as the intermediate-impact of query $q_i$ on query $q_j$
($j > i$) and $\mathcal{F}_j(q_i)$ is defined as follows. \[
\mathcal{F}_j(q_i)=\mathcal{F}_{j-1}(q_i)\bigcup_{\substack{\mathcal{F}_{j-1}(q_i)\cap
\mathcal{P}(q_j) \neq \emptyset}} \mathcal{I}(q_j), \] With initial impact
$\mathcal{F}_i(q_i) = \mathcal{I}(q_i)$. The full-impact of $q_i$,
$\mathcal{F}(q_i)$ is indeed the impact on the final query $q_n$,
$\mathcal{F}_n(q_i)$: \[ \mathcal{F}(q_i)=\mathcal{F}_n(q_i) =
\mathcal{I}_(q_i)\bigcup_{\substack{j = i+1 \\ \mathcal{F}_{j-1}(q_i)\cap
\mathcal{P}(q_j) \neq \emptyset}}^n \mathcal{I}(q_j), \]

For example, in the following query log (example mentioned in reviews):\\
\textit{\indent q1 writes t.A; \\
\indent q2 reads t.A and writes u.B; \\
\indent q3 reads u.B and writes v.C.}\\
\[\mathcal{F}_1(q_1) = \{t.A\};\] 
\[\mathcal{F}_2(q_1) = \{t.A\} \bigcup_{\mathcal{F}_1(q_1) \cap \{t.A\} \neq \emptyset} \{u.B\} = \{t.A, u.B\};\]
\[\mathcal{F}_3(q_1) = \{t.A, u.B\}\bigcup_{\mathcal{F}_2(q_2) \cap \{u.B\} \neq \emptyset} \{v.C\} = \{t.A, u.B, v.C\}.\]
Thus the full-impact of $q_1$ is $\{t.A, u.B, v.C\}$.




\comskip

\noindent
\textbf{Comment \#3:} Experiments on large datasets
\begin{quote}
\reviewer{
Do the experiments substantiate the claim of scalability to ``large''
databases of 100k records? If so the experimental evaluation needs to explain
this more clearly. If not the introduction must avoid overselling this point.

\dots

Experimental evaluation doesn't live up to claims in introduction (5-6K
records vs. 100K)

\dots

the experiments only seem to consider much smaller databases (5000-6000
tuples).

}
\end{quote}

Again, we apologize for inconsistency between our scalability statement and
experiments in the main text and our statement was based on experiments in
Appendix~\ref{sec:heuristic}.

In addition, we extend our scalability experiment in Figure~\ref{f:attr100} to
databases with $100k$ records and demonstrate that even with the most complex
setting, \texttt{UPDATE} queries with \textit{range} \texttt{WHERE} clause,
\sys scales to databases with $100k$ records when the corruption age is as old
as $250$.

\alex{Say more about the inconsistency between intro and evaluation.}


\comskip

\noindent
\textbf{Comment \#4:} Why $M^+$ in \texttt{DELETE} query?
\begin{quote}
\reviewer{
It's also not entirely clear why it is correct to use a ``large/unused'' value $M^+$ for attributes of deleted tuples.

\dots

p5. Handling DELETE using $M^+$. \dots I'm not sure I understand why this the
case and if so, why it is correct. \dots for example if the test is ``t.A > 5'' then setting t.A to $M^+$ (assuming it's bigger than 5) will not invalidate the test.

}
\end{quote}

\alex{Make sure to address both points!}

For clarification we rename the former variable $M^+$ as $M^-$ to distinguish
from $M$ and emphasis its relationship with $M$ as $M^- \leq M$. $M^-$ is set
to a large enough number outside the attribute domain in order to guarantee
that \sys would fix the incorrect \texttt{DELETE} query instead of its
consecutive \texttt{UPDATE} queries. Recall our MILP encoding in Equation 6,
to ensure that the attribute value of tuple is set to $M^-$ in a
\texttt{DELETE} query, one need to set $x_{q_i,t} = 1$ which only requires
variable adjustment in the \texttt{WHERE} clause such that $\sigma_{q_i}(t) =
1$. Alternatively, it may also feasible to manipulate the consecutive
\texttt{UPDATE} query such that the \texttt{SET} clause updates the tuple to
$M^-$ as $\mu_{q_i}(t) = M^-$ (according to Equation 4). Modifying
\texttt{DELETE} query or \texttt{UPDATE} query may all lead to feasible
solution, however, different objective-function values are associated with
them. By setting $M^-$ to a ``sufficiently large'' number, we force the
objective-function value of the \texttt{UPDATE} query modification exceedingly
large than the \texttt{DELETE} query's. Thus it is guaranteed that \sys will
always fix the incorrect \texttt{DELETE} query instead of its consecutive
\texttt{UPDATE} queries. In addition, we set $M^- \leq M$ to avoid generating
infeasibility conditions.

Note that for workloads with both \texttt{DELETE} and \texttt{UPDATE} queries.
The assignment of $x_{q_i, t}$ in a \texttt{UPDATE} query 
(with no \texttt{WHERE} clause) requires the following change:
\begin{align}
\label{eq:x2}
x_{q_i, t} = x'_{q_i, t} \otimes 0 + (1-x'_{q_i, t}) \otimes \sigma_{q_i}(t) \nonumber \\
x'_{q_i, t}= (t.A_j = M^-) \wedge (t.A_j^* = M^-) 
\end{align}
This arrangement avoid generating invalid MILP problems:
by doing so, a deleted tuple having $t.A_j = M^-$ on all attributes leads to 
$x'_{q_i, t} = 1$ and $x_{q_i, t}  = 0$ on all the following \texttt{UPDATE} queries. 
In the example in reviewer mentioned in $p5$, suppose a tuple is deleted and values in all attributes are assigned to $M^-$. 
The boolean variable $x'_{q_i, t}$ is set to $1$ and $x_{q_i, t} $ to $0$ for any following \texttt{UPDATE} queries regardless
of their \texttt{WHERE} predicate. Thus, \texttt{UPDATE} queries won't updates values for already deleted tuples. 

\comskip

\noindent
\textbf{Comment \#5:} Assumptions
\begin{quote}
\reviewer{
Problem specification seems restrictive (users need to provide complete,
correct rows as complaints).

\dots

p3. Please clarify whether a complaint needs to specify exact fix values for all fields \dots 
}
\end{quote}

While in the paper we use exact fix values for all fields of a complaint, we
only do so for ease of exposition, and this is actually not a limitation in
our techniques. We have added clarification about this in
Section~\ref{sec:model}.



\comskip

\noindent
\textbf{Comment \#6:} Additional corrections and clarifications

\smallskip

We thank the reviewers for the many detailed comments. We have corrected the
typos, and reworded confusing sentences. We also provide some further notes on
some of the detailed comments below.

\begin{quote}
\reviewer{
p2. Although it is just an example, it does seem like questionable design for
the tax rates for different salary levels to be stored in the query rather
than in the database.
}
\end{quote}

The example is emulating a form-based entry of the tax-rate information, but
we agree that in practice the design would be much more complex. We chose a
substantial simplification to make the example easy to follow and to allow us
to more easily highlight the contributions of our work.

\begin{quote}
\reviewer{
p2. The figures in the example seem wrong (ironically) \dots
}
\end{quote}

Thank you for noting this mistake. We corrected the figure to have the
correct numbers.


\begin{quote}
\reviewer{
p3. This is explained later, but please clarify that the expressions used in
mu and sigma are from a limited language (e.g. arithmetic).
}
\end{quote}

\alex{Have we done anything about this?} \xlw{The explanation and definition is
quite close. We give def and then description. Maybe we should switch the order?}


\begin{quote}
\reviewer{
p3. What does notation ``$D \setminus\{t\}$'' mean (in def 3) if $t = \bot$? No-op? Also,
t* should be allowed to range over $D \cup \{\bot\}$ also to allow for deletion
(as discussed on the next page).
}
\end{quote}

We correct our definition on range of $t$ and $t^*$ as $D \cup \{\bot\}$. The transformation of 
a database state $\mathcal{T}_c(D)$ excludes the complaint tuple $\{t\}$ and replace it with 
$t^*$ with correct values. If $t = \bot$, it means tuple $t$ does not exist in the original
database and should be added into the database; similarly if $t^* = \bot$, the tuple $t$ is in
the original database but should be removed. 

\alex{Have we done anything about this?}

\begin{quote}
\reviewer{
p4. The paper often refers to ``data manipulation queries'', which sounds
self-contradictory to me (a query reads, an update writes). Perhaps just
``updates'' instead of ``data manipulation queries'' ?
}
\end{quote}

We change it as ``data manipulation statements'' that include \texttt{UPDATE},
\texttt{INSERT}, and \texttt{DELETE} queries. We intentionally avoid naming 
them ``update queries'' in order to distinguish from the \texttt{UPDATE} query. 

\alex{This term is only used once in the paper. How about we just change it to
data manipulation statements?}


\begin{quote}
\reviewer{
p5. How strongly does the performance of the MILP solver depend on M (the
upper bound chosen on the value of a given numeric field)? Presumably,
choosing the largest machine-representable number would lead to overflow
problems?
}
\end{quote}

To guarantee the correctness of the \texttt{UPDATE} queries, $M$ must 
be assigned to a value outside the domain range of the corresponding attribute 
because constraints in ~\ref{eq:uv} will be self-contradictory otherwise. For example, 
attribute \textit{human age} has a domain range of $[0, 200]$, in which case $M$ must be 
set to a value that is above $200$. 
In addition, in order to maintain the feasibility for workloads with \texttt{DELETE}
queries, $M$ must be set to a value that is $\geq M^-$ (we explained
the setting of $M^-$ in Comment\# 4), but not necessary a 
upper bound of the given numeric field. 

\alex{Have we done anything about this?}


\begin{quote}
\reviewer{
p5. In (5), should v be u?
}
\end{quote}

We thank the reviewer for noting this, we correct this typo in the paper. 
\alex{(5) does not seem to have changed. If it does not need to be changed, we
should explain here why.} 


\begin{quote}
\reviewer{
p7. ``Figure 3 showed the exponential cost'' - the scaling from 40 to 60 to 80 looked linear to me, just with a high coefficient.}
\end{quote}
We apologize for not stating it clear. In Figure~\ref{fig:querysize_vs_time}, \naive fails to produce an answer
 for problems with $\geq 80$ queries within 1000 sec and \naive shows exponential cost for problems with $20$, $40$, and $60$ queries. 
\alex{What is the answer here?}


\begin{quote}
\reviewer{
p10. Fig. 8 - please add 0.75 (the largest x-axis value) to the x-axis, better yet, label the x-axis with the rate values that correspond to data points.
}
\end{quote}

We thank the reviewer for the detailed suggestion and we implement this in our main text. 

\begin{quote}
\reviewer{
p10. ``may suffer if the corruption occured in a very old query'' - does it (and are you saying fig. 8 supports this claim)?

p10. ``may over-generalize'' - again, are you speculating or interpreting the results here?
}
\end{quote}

We observe from Figure~\ref{f:falsenegative_acc} that \sys derives inaccurate log repairs when the corruption occured in 
very old query  \textit{corruption age = 250}). Also, if there are insufficient complaints, then it is possible that the 
repair will over-generalize to  ``repair'' the wrong records and lead to lower precision.

\alex{What have we done for this?} \xlw{We added some clarification in the text. }

\begin{quote}
\reviewer{
p10, footnote: this seems like a strong assumption! I guess this means that dealing with multiple errors that interact with each other is future work...
}
\end{quote}

We clarify this assumption in Section~\ref{sec:abstractions}. Currently, we cannot apply incremental algorithm 
on problems with multiple corruptions since errors may spread across the entire query history, \sys 
does not scale over problems with more than 40 queries. We leave further improvement in our future work.

\alex{We need to say something here.  Have we clarified this assumption early in the paper?}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
